# -*- coding: utf-8 -*-
"""RAHF_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQSm0-C9TBWVDIHHyqgtfpoYC42esbTs
"""

import torch
import torch.nn as nn

from transformers import AutoProcessor, AutoModel, AutoConfig

from .basic_components import Residual, Attention, FeedForward
import torch.nn.functional as F


class VisionTransformer(nn.Module):
  def __init__(self, pretrained_model, freeze, new_position_embedding_weight):
    super(VisionTransformer, self).__init__()
    self.ViT = pretrained_model.vision_model
    self.new_position_embedding_weight = new_position_embedding_weight
    # 插值vit embeddings
    # self.interpolate_embeddings()
    self.load_interpolate_embeddings()

    self.freeze = freeze
    if self.freeze:
      for param in self.ViT.parameters():
        param.requires_grad = False
    else:
      for param in self.ViT.post_layernorm.parameters():
        param.requires_grad = False

  def forward(self, x):
    x = self.ViT(x)
    return x 

  def unfreeze(self):
    for param in self.ViT.parameters():
      param.requires_grad = True
    for param in self.ViT.post_layernorm.parameters():
      param.requires_grad = False
    # 使用siglip时需要
    # for param in self.ViT.head.parameters(): # unused
    #       param.requires_grad = False
  
  def load_interpolate_embeddings(self):
    with torch.no_grad():
      self.ViT.embeddings.position_embedding.weight.copy_(self.new_position_embedding_weight)

  def interpolate_embeddings(self):
    self.ViT.embeddings.position_ids = torch.arange(1025).unsqueeze(0)
    position_embedding = self.ViT.embeddings.position_embedding.weight
    cls_pos,ori_pos = position_embedding[0], position_embedding[1:]
    ori_pos = ori_pos.view(16,16,-1).unsqueeze(0).permute(0,3,1,2)

    resized_pos = F.interpolate(ori_pos, size=(32, 32), mode='bilinear')
    resized_pos = resized_pos.squeeze(0).permute(1,2,0).view(1024,-1)
    new_position_embedding_weight = torch.cat((cls_pos.unsqueeze(0),resized_pos),dim=0)
    new_position_embedding = nn.Embedding(1025, 1024)
    with torch.no_grad():
      new_position_embedding.weight.copy_(new_position_embedding_weight)
    self.ViT.embeddings.position_embedding = new_position_embedding

class TextEmbedding(nn.Module):
  def __init__(self, pretrained_model, freeze):
    super(TextEmbedding, self).__init__()

    # AltCLIP
    self.text_embedding = pretrained_model.text_model.roberta.embeddings
    self.freeze = freeze
    if self.freeze:
      for param in self.text_embedding.parameters():
        param.requires_grad = False

  def forward(self, x):
    x = self.text_embedding(x)
    return x

  def unfreeze(self):
    for param in self.text_embedding.parameters():
      param.requires_grad = True



class LayerPair(nn.Module):
    def __init__(self, dim, hidden_dim):
        super(LayerPair, self).__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attention = Residual(Attention(dim))
        self.norm2 = nn.LayerNorm(dim)
        self.feed_forward = Residual(FeedForward(dim, hidden_dim))

    def forward(self, x):
        x = self.norm1(x)
        x = self.attention(x)
        x = self.norm2(x)
        x = self.feed_forward(x)
        return x

class SelfAttention(nn.Module):
  def __init__(self, num_layers=6, dim=768, hidden_dim=2048):
    super(SelfAttention, self).__init__()
    self.layers = nn.ModuleList([LayerPair(dim, hidden_dim) for _ in range(num_layers)])
    self.norm = nn.LayerNorm(dim)

  def forward(self, x):
    for layer in self.layers:
      x = layer(x)
    return self.norm(x)

class HeatmapPredictor(nn.Module):
  def __init__(self, conv_info = [768, 384, 384], deconv_info=[384, 768, 384, 384, 192]):
    super(HeatmapPredictor, self).__init__()
    self.filter_size = deconv_info
    self.conv_layers = nn.Sequential(
      nn.Conv2d(in_channels=conv_info[0], out_channels=conv_info[1], kernel_size=(3, 3), stride=(1, 1), padding=1),
      nn.LayerNorm([conv_info[1], 32, 32]),
      nn.ReLU(),
      nn.Conv2d(in_channels=conv_info[1], out_channels=conv_info[2], kernel_size=(3, 3), stride=(1, 1), padding=1),
      nn.LayerNorm([conv_info[2], 32, 32]),
      nn.ReLU()
    )
    self.deconv_layers = nn.ModuleList([
      nn.ModuleList([
        nn.ConvTranspose2d(in_channels=self.filter_size[i],
                           out_channels=self.filter_size[i+1],
                           kernel_size=(3, 3),
                           stride=(2, 2),
                           padding=1, output_padding=1),
        nn.LayerNorm([self.filter_size[i+1], 32*2**(i+1), 32*2**(i+1)]),
        nn.ReLU(),
        nn.Conv2d(in_channels=self.filter_size[i+1],
                  out_channels=self.filter_size[i+1],
                  kernel_size=(3, 3), stride=(1, 1), padding=1),
        nn.LayerNorm([self.filter_size[i+1], 32*2**(i+1), 32*2**(i+1)]),
        nn.ReLU(),
        nn.Conv2d(in_channels=self.filter_size[i+1],
                  out_channels=self.filter_size[i+1],
                  kernel_size=(3, 3), stride=(1, 1), padding=1),
        nn.LayerNorm([self.filter_size[i+1], 32*2**(i+1), 32*2**(i+1)]),
        nn.ReLU(),
      ]) for i in range(len(self.filter_size)-1)
    ])
    self.final_layers = nn.Sequential(
      nn.Conv2d(in_channels=self.filter_size[-1], out_channels=1, kernel_size=(3, 3), stride=(1, 1), padding=1),
      nn.Sigmoid()
    )

  def forward(self, x):
    x = self.conv_layers(x)
    for layer in self.deconv_layers:
      for deconv in layer:
        x = deconv(x)
    x = self.final_layers(x)
    return x

class ScorePredictor(nn.Module):
    def __init__(self, filter_info=[768, 768, 384, 128, 64]):
        super(ScorePredictor, self).__init__()
        self.filter_size = filter_info
        self.conv_layers = nn.ModuleList([
            nn.ModuleList([
                nn.Conv2d(in_channels=self.filter_size[i],
                          out_channels=self.filter_size[i + 1],
                          kernel_size=(2, 2), stride=(1, 1)),
                nn.LayerNorm([self.filter_size[i + 1], 32-(i+1), 32-(i+1)]),
                nn.ReLU(),
            ]) for i in range(len(self.filter_size) - 1)
        ])
        self.flatten_size = self.filter_size[-1] * (32-(len(self.filter_size)-1))**2
        self.fc_layers = nn.Sequential(
            nn.Linear(in_features=self.flatten_size, out_features=2048),
            nn.ReLU(),
            nn.Linear(in_features=2048, out_features=1024),
            nn.ReLU(),
            nn.Linear(in_features=1024, out_features=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        for layers in self.conv_layers:
            for layer in layers:
                x = layer(x)
        x = torch.flatten(x, start_dim=1)
        x = self.fc_layers(x)
        return x

class RAHF(nn.Module):
  def __init__(self, pretrained_model_path, freeze):
    super(RAHF, self).__init__()
    # interpolate = True if 'altclip' in pretrained_model_path else False
    pretrained_config = AutoConfig.from_pretrained(pretrained_model_path)
    pretrained_config.vision_config.image_size = 448
    pretrained_model = AutoModel.from_pretrained(pretrained_model_path, config=pretrained_config, ignore_mismatched_sizes=True)
    new_position_embedding_weight = torch.load(f"{pretrained_model_path}/new_position_embedding_weight_448.pt")
    self.image_encoder = VisionTransformer(pretrained_model, freeze, new_position_embedding_weight)
    self.text_encoder = TextEmbedding(pretrained_model, freeze)
    self.self_attention = SelfAttention(dim=1024, hidden_dim=2048)
    self.heatmap_predictor = HeatmapPredictor(conv_info = [1024, 512, 512], deconv_info=[512, 1024, 512, 512, 256])
    self.score_predictor = ScorePredictor(filter_info=[1024, 1024, 512, 128, 64])

  def forward(self, image, prompt, need_score=True):
    image_token = self.image_encoder(image).last_hidden_state
    text_token = self.text_encoder(prompt)
    x = torch.cat([image_token, text_token], dim=1)
    x = self.self_attention(x)
    feature_map = x[:, 1:1025, :].clone().view(-1, 32, 32, 1024).permute(0, 3, 1, 2)
    heatmap = self.heatmap_predictor(feature_map)

    if not need_score:
      return heatmap
    else:
      score = self.score_predictor(feature_map)
      return heatmap, score
  
if __name__ == "__main__":
    model = RAHF()